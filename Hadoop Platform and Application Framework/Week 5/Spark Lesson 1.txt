Week 5 Quiz 1
Spark Lesson 1

1. Apache Spark was developed in order to provide solutions to shortcomings of another project, and eventually replace it. What is the name of this project?
A.MapReduce

2. Why is Hadoop MapReduce slow for iterative algorithms?
A. It needs to read off disk for every iteration

3. What is the most important feature of Apache Spark to speedup iterative algorithms?
A. Caching datasets in memory

4. Which other Hadoop project can Spark rely to provision and manage the cluster of nodes?
A. YARN

5. When Spark reads data out of HDFS, what is the process that interfaces directly with HDFS?
A. Executor

6. Under which circumstances is preferable to run Spark in Standalone mode instead of relying on YARN?
A.When you only plan on running Spark jobs